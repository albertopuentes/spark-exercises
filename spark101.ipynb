{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import col, expr\n",
    "from pyspark.sql.functions import *\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=['python', 'HTML', 'Java', 'Solidity', 'R'], columns=['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "print((spark_df.count(), len(spark_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|    HTML|\n",
      "|    Java|\n",
      "|Solidity|\n",
      "|       R|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create 1 column of output that contains a message like the one below: The 1999 audi a4 has a 4 cylinder engine.  For each vehicle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|   trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|auto(l5)|  f| 18| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+--------+---+---+---+---+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "mpg.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+-------------------------------------------------------------+\n",
      "|manufacturer|model             |displ|year|cyl|trans     |drv|cty|hwy|fl |class  |desc                                                         |\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+-------------------------------------------------------------+\n",
      "|audi        |a4                |1.8  |1999|4  |auto(l5)  |f  |18 |29 |p  |compact|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|audi        |a4                |1.8  |1999|4  |manual(m5)|f  |21 |29 |p  |compact|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|audi        |a4                |2.0  |2008|4  |manual(m6)|f  |20 |31 |p  |compact|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|audi        |a4                |2.0  |2008|4  |auto(av)  |f  |21 |30 |p  |compact|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|audi        |a4                |2.8  |1999|6  |auto(l5)  |f  |16 |26 |p  |compact|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|audi        |a4                |2.8  |1999|6  |manual(m5)|f  |18 |26 |p  |compact|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|audi        |a4                |3.1  |2008|6  |auto(av)  |f  |18 |27 |p  |compact|The 2008 audi a4 has a 6cylinder engine.                     |\n",
      "|audi        |a4 quattro        |1.8  |1999|4  |manual(m5)|4  |18 |26 |p  |compact|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|audi        |a4 quattro        |1.8  |1999|4  |auto(l5)  |4  |16 |25 |p  |compact|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|audi        |a4 quattro        |2.0  |2008|4  |manual(m6)|4  |20 |28 |p  |compact|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|audi        |a4 quattro        |2.0  |2008|4  |auto(s6)  |4  |19 |27 |p  |compact|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|audi        |a4 quattro        |2.8  |1999|6  |auto(l5)  |4  |15 |25 |p  |compact|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|audi        |a4 quattro        |2.8  |1999|6  |manual(m5)|4  |17 |25 |p  |compact|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|audi        |a4 quattro        |3.1  |2008|6  |auto(s6)  |4  |17 |25 |p  |compact|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|audi        |a4 quattro        |3.1  |2008|6  |manual(m6)|4  |15 |25 |p  |compact|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|audi        |a6 quattro        |2.8  |1999|6  |auto(l5)  |4  |15 |24 |p  |midsize|The 1999 audi a6 quattro has a 6cylinder engine.             |\n",
      "|audi        |a6 quattro        |3.1  |2008|6  |auto(s6)  |4  |17 |25 |p  |midsize|The 2008 audi a6 quattro has a 6cylinder engine.             |\n",
      "|audi        |a6 quattro        |4.2  |2008|8  |auto(s6)  |4  |16 |23 |p  |midsize|The 2008 audi a6 quattro has a 8cylinder engine.             |\n",
      "|chevrolet   |c1500 suburban 2wd|5.3  |2008|8  |auto(l4)  |r  |14 |20 |r  |suv    |The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "|chevrolet   |c1500 suburban 2wd|5.3  |2008|8  |auto(l4)  |r  |11 |15 |e  |suv    |The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "+------------+------------------+-----+----+---+----------+---+---+---+---+-------+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg2 = mpg.select('*', concat(lit('The '), mpg.year,lit(' '), mpg.manufacturer, lit(' '), mpg.model, lit(' has a '), mpg.cyl, lit('cylinder engine.')).alias('desc')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------------------------------------------------------------------+\n",
      "|     trans|CASE WHEN ((trans = manual(m5)) OR (trans = manual(m6))) THEN manual ELSE auto END|\n",
      "+----------+----------------------------------------------------------------------------------+\n",
      "|  auto(l5)|                                                                              auto|\n",
      "|manual(m5)|                                                                            manual|\n",
      "|manual(m6)|                                                                            manual|\n",
      "|  auto(av)|                                                                              auto|\n",
      "|  auto(l5)|                                                                              auto|\n",
      "|manual(m5)|                                                                            manual|\n",
      "|  auto(av)|                                                                              auto|\n",
      "|manual(m5)|                                                                            manual|\n",
      "|  auto(l5)|                                                                              auto|\n",
      "|manual(m6)|                                                                            manual|\n",
      "|  auto(s6)|                                                                              auto|\n",
      "|  auto(l5)|                                                                              auto|\n",
      "|manual(m5)|                                                                            manual|\n",
      "|  auto(s6)|                                                                              auto|\n",
      "|manual(m6)|                                                                            manual|\n",
      "|  auto(l5)|                                                                              auto|\n",
      "|  auto(s6)|                                                                              auto|\n",
      "|  auto(s6)|                                                                              auto|\n",
      "|  auto(l4)|                                                                              auto|\n",
      "|  auto(l4)|                                                                              auto|\n",
      "+----------+----------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(mpg.trans, when((mpg.trans == 'manual(m5)') | (mpg.trans == 'manual(m6)'), 'manual').otherwise(\"auto\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tips dataset as a spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "\n",
    "tips = spark.createDataFrame(data(\"tips\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column that contains the tip percentage. Load the tips dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_pct = tips.tip / tips.total_bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|            tip_pct|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips = tips.select('*', tip_pct.alias('tip_pct'))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy(\"smoker\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|smoker|count|               perc|\n",
      "+------+-----+-------------------+\n",
      "|    No|  151| 0.6188524590163934|\n",
      "|   Yes|   93|0.38114754098360654|\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('smoker').count().withColumn('perc', ((col('count'))/(tips.count()))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-------------------+\n",
      "|smoker|             Female|               Male|\n",
      "+------+-------------------+-------------------+\n",
      "|    No| 0.1569209707691836| 0.1606687151291298|\n",
      "|   Yes|0.18215035269941032|0.15277117520248512|\n",
      "+------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('smoker').pivot('sex').agg(mean('tip_pct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert the temperatures to fahrenheit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+------------------+------------------+----+-------+\n",
      "|      date|precipitation|          temp_max|          temp_min|wind|weather|\n",
      "+----------+-------------+------------------+------------------+----+-------+\n",
      "|2012-01-01|          0.0|55.040000000000006|              41.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|             51.08|             37.04| 4.5|   rain|\n",
      "|2012-01-03|          0.8|             53.06|             44.96| 2.3|   rain|\n",
      "|2012-01-04|         20.3|             53.96|             42.08| 4.7|   rain|\n",
      "|2012-01-05|          1.3|48.019999999999996|             37.04| 6.1|   rain|\n",
      "|2012-01-06|          2.5|             39.92|             35.96| 2.2|   rain|\n",
      "|2012-01-07|          0.0|             44.96|             37.04| 2.3|   rain|\n",
      "|2012-01-08|          0.0|              50.0|             37.04| 2.0|    sun|\n",
      "|2012-01-09|          4.3|             48.92|              41.0| 3.4|   rain|\n",
      "|2012-01-10|          1.0|42.980000000000004|             33.08| 3.4|   rain|\n",
      "|2012-01-11|          0.0|42.980000000000004|             30.02| 5.1|    sun|\n",
      "|2012-01-12|          0.0|42.980000000000004|             28.94| 1.9|    sun|\n",
      "|2012-01-13|          0.0|              41.0|             26.96| 1.3|    sun|\n",
      "|2012-01-14|          4.1|             39.92|             33.08| 5.3|   snow|\n",
      "|2012-01-15|          5.3|             33.98|26.060000000000002| 3.2|   snow|\n",
      "|2012-01-16|          2.5|             35.06|             26.96| 5.0|   snow|\n",
      "|2012-01-17|          8.1|             37.94|              32.0| 5.6|   snow|\n",
      "|2012-01-18|         19.8|              32.0|             26.96| 5.0|   snow|\n",
      "|2012-01-19|         15.2|             30.02|             26.96| 1.6|   snow|\n",
      "|2012-01-20|         13.5|             44.96|             30.02| 2.3|   snow|\n",
      "+----------+-------------+------------------+------------------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather2 = weather.withColumn('temp_max', col('temp_max') * 1.8 + 32).withColumn('temp_min', col('temp_min') * 1.8 +32).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+\n",
      "|month|       avg_rainfall|\n",
      "+-----+-------------------+\n",
      "|   11|  5.354166666666667|\n",
      "|   12|  5.021774193548389|\n",
      "|    3|  4.888709677419355|\n",
      "|   10|  4.059677419354839|\n",
      "|    1| 3.7580645161290316|\n",
      "|    2|  3.734513274336283|\n",
      "|    4|  3.128333333333333|\n",
      "|    9| 1.9624999999999997|\n",
      "|    5| 1.6733870967741935|\n",
      "|    8| 1.3201612903225806|\n",
      "|    6| 1.1075000000000002|\n",
      "|    7|0.38870967741935486|\n",
      "+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\"month\", month(\"date\")).groupBy(\"month\").agg(mean(\"precipitation\").alias(\"avg_rainfall\")).sort(desc(\"avg_rainfall\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|year|        total_wind|\n",
      "+----+------------------+\n",
      "|2012|            1244.7|\n",
      "|2014|1236.5000000000007|\n",
      "|2015|1153.3000000000002|\n",
      "|2013|1100.8000000000006|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.withColumn('year', year('date'))\n",
    ".groupby('year')\n",
    ".agg(sum('wind').alias('total_wind'))\n",
    ".sort(col(\"total_wind\").desc())\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|weather|count(weather)|\n",
      "+-------+--------------+\n",
      "|    fog|            38|\n",
      "|   rain|            35|\n",
      "|    sun|            33|\n",
      "|drizzle|            10|\n",
      "|   snow|             8|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(month('date') == 1)\n",
    ".groupby('weather')\n",
    ".agg(count('weather'))\n",
    ".sort(col(\"count(weather)\").desc())\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "| average_high_temp| average_low_temp|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(month('date')==7)\n",
    ".filter(year('date')>2012)\n",
    ".filter(year('date')<2015)\n",
    ".filter(col('weather')==lit('sun'))\n",
    ".agg(avg(\"temp_max\").alias(\"average_high_temp\"), avg(\"temp_min\").alias(\"average_low_temp\"))\n",
    ".show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          avg(rainy)|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(year('date')==2015)\n",
    ".filter(month('date')>6)\n",
    ".filter(month('date')<10)\n",
    ".select(when(col(\"weather\") == \"rain\", 1).otherwise(0).alias('rainy'))\n",
    ".agg(mean(\"rainy\"))\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|          avg(prec)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.withColumn('year', year('date'))\n",
    ".select(when(col(\"precipitation\") > 0, 1).otherwise(0).alias('prec'), 'year')\n",
    ".groupby('year')\n",
    ".agg(mean('prec'))\n",
    ".sort(desc(col('avg(prec)')))\n",
    ".show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
